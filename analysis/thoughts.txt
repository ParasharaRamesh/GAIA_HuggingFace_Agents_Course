List of tools I need:

    File reading tools:

    1. Parse Excel as a DataFrame in python (code agent can do this)
    2. Parse MP3 -> TTS (X)
    3. Parse Youtube url -> audio -> transcript (X)
    4. Parse Youtube url -> video (X) -> analysis
    5. Parse Images (use multimodal LLM)

    Search Tools: (X)

    1. web browser for search
    2. web scraper
    3. wikipedia scraper (perhaps the code agent can do it)
    4. Arxiv tools (academic journal scraper)

    Code Agent:

    1. python code agent ( should cover all math )

    Generic Agent:
    . just gives some answer

    RAG/Local vector db: (not needed!)

    - Needed for indexing the web page results/wiki page results maybe?

Agents workflow diagram refer to analysis/visualization.ipynb

Thoughts/Potential TODOS:

. will the planner guarantee that it can use code agent whenever it wants using the output of another agent?
. can use vjepa and vjepa 2 for visual analysis tools
. return only a part of the chunk (example summary if present) to the LLM context window while indexing the rest into the DB
. use langfuse for debugging
. perhaps a requests tool, this way it would have the tools download anything and if need be save it.

Important Links:

* https://huggingface.co/datasets/gaia-benchmark/GAIA
* https://huggingface.co/learn/agents-course/unit4/introduction
* https://huggingface.co/blog/open-deep-research
* https://github.com/huggingface/smolagents/blob/main/examples/open_deep_research/scripts/text_inspector_tool.py
* https://python.langchain.com/docs/integrations/tools/
* Refer to that article from langgraph which talks about how to build multi agent systems (swarm)


TODO:

Got it! Thanks for the clarification. Your points are valid and important for creating a truly robust orchestrator.

Let's address them:

1.  **Supervisor Prompt - `Action Input` with Multiple Sub-Steps for the Sub-Agent:**
    * **Yes, this is a very strong improvement!** You're absolutely right. While the `Action Input` should be concise, it can indeed outline a "mini-plan" or sequential sub-tasks *if* that sub-task itself is inherently complex and benefits from a structured approach, even within a single delegation to a specialized agent.
    * **Example:** Instead of `researcher[Find climate change stats]` you might have `researcher[First, find global temperature anomalies between 1980-2020. Second, find sea level rise data for the same period. Third, identify sources of greenhouse gas emissions.]`
    * This empowers the sub-agent to follow a clearer internal path without needing to rely solely on its own emergent reasoning for structuring a complex task. It also ensures the supervisor provides sufficient guidance for that particular delegation.
    * We'll incorporate this into the supervisor's prompt instructions.

2.  **Supervisor Prompt - Acknowledging Agent's Ability to Ask for Help if Stuck:**
    * **Absolutely, this is essential for robustness!** The supervisor needs to be aware that agents might return a "stuck" signal. Its prompt should include instructions on:
        * Recognizing the "STUCK" format (e.g., `Final Answer: STUCK - [Reason]`).
        * How to react to it (e.g., ask clarifying questions back to the user, try a different approach, delegate to a different agent, or even re-try with more context/guidance).
    * This creates a feedback loop and prevents the system from silently failing when a sub-agent hits an unresolvable issue.

### Revised High-Level Plan (Incorporating your clarifications):

The overall structure remains the same, but the content of the prompt changes in Steps 3 and 4 will be updated to reflect these new capabilities.

1.  **Step 1: Create the `_clean_agent_messages_hook` Utility Function.**
    * We'll create a new Python file (e.g., `utils/message_cleaner.py`) and provide the Python code for the function.

2.  **Step 2: Update Sub-Agent Prompt Loading and `ChatPromptTemplate` Construction.**
    * Modify agent files (`audio.py`, `interpreter.py`, `researcher.py`, `visual.py`, `generic.py`):
        * Adjust `react_prompt_content` to contain *only* the System Message.
        * Change `ChatPromptTemplate.from_template(...)` to `ChatPromptTemplate.from_messages(...)`.
        * Integrate the `_clean_agent_messages_hook` using `pre_model_hooks`.
    * I'll provide an example for one agent.

3.  **Step 3: Refine the Supervisor's Prompt (`orchestrator_prompt.txt`).**
    * Update `Action Input` instructions to guide the supervisor in creating concise tasks that *can include sub-steps or mini-plans* for the delegated agent.
    * **Add new instructions** for the supervisor to understand and act upon "STUCK" messages from sub-agents.
    * Provide the updated content for `orchestrator_prompt.txt`.

4.  **Step 4: Refine All Sub-Agent Prompts (`*_react_prompt.txt` files).**
    * For *each* sub-agent's prompt file:
        * Reinforce focus on the `input` (now potentially a mini-plan).
        * Instruct to include a concise summary in `Final Answer:`.
        * **Add clear instructions on how to signal being "STUCK"** to the supervisor.
    * I'll provide updated content for each of these prompt files.

This looks like a robust and well-thought-out plan. Are you ready to start with **Step 1**?

